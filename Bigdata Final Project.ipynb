{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05cfe428-2a7a-48b6-aa48-8259bcbfdabb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"Forecasting the Future of Healthcare Costs\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8857833-60e2-4d9e-91fa-2f36a45acf14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df=spark.read.csv(\"/FileStore/tables/synthetic_healthcare_costs_large.csv\",inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14ab9cf9-925a-4b66-a173-1bb9ae36ddee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------+-----------+------------------+-------------+--------------+-----------------+---------+---------------+-------------------+--------------+------------------+-----------+----------------+-------------+-----------------+----+-------+\n|PatientID|Age|Gender|IncomeLevel|         Diagnosis|TreatmentType|NumberOfVisits|TreatmentDuration|TotalCost|OutOfPocketCost|HospitalizationDays|MedicationCost|DiagnosticTestCost|SurgeryCost|ChronicCondition|FamilyHistory|InsuranceCoverage|Year|Quarter|\n+---------+---+------+-----------+------------------+-------------+--------------+-----------------+---------+---------------+-------------------+--------------+------------------+-----------+----------------+-------------+-----------------+----+-------+\n|   P00001| 76|Female|        Low|Respiratory Issues|   Medication|             6|                3| 17263.84|        4003.07|                  2|       2251.03|            472.54|    7199.77|             Yes|          Yes|          Partial|2023|     Q4|\n+---------+---+------+-----------+------------------+-------------+--------------+-----------------+---------+---------------+-------------------+--------------+------------------+-----------+----------------+-------------+-----------------+----+-------+\nonly showing top 1 row\n\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3d03ffc-95f4-494a-9ec1-a949ca375699",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n|Age|           AvgCost|\n+---+------------------+\n| 31|14999.602296296298|\n| 85|15242.566338028166|\n| 65|14492.644895104902|\n| 53|15421.605395683446|\n| 78| 15289.47901408451|\n| 34|14297.321241830068|\n| 81|14865.634318181821|\n| 28|      15076.790625|\n| 76| 14832.88061224491|\n| 27|14801.118895705533|\n| 26|15150.798417266187|\n| 44| 14005.59322147652|\n| 22|15329.355359477126|\n| 47|14989.994085365857|\n| 52| 14651.38704918032|\n| 86|14974.679275362316|\n| 20|15387.520000000002|\n| 40|14624.245447761194|\n| 57|14735.550937500004|\n| 54|14621.762166666671|\n+---+------------------+\nonly showing top 20 rows\n\n+------+------------------+\n|Gender|           AvgCost|\n+------+------------------+\n|Female|14979.845273069628|\n| Other|14730.580313252995|\n|  Male|14910.906579275907|\n+------+------------------+\n\n+-----------+------------------+\n|IncomeLevel|           AvgCost|\n+-----------+------------------+\n|       High|14844.726505964236|\n|        Low|14967.357999999971|\n|     Middle|14951.889710996813|\n+-----------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "1 # Analyze healthcare costs across demographics, treatments, and diagnoses\n",
    "from pyspark.sql.functions import col, avg, sum, count\n",
    "df.groupBy(\"Age\").agg(avg(\"TotalCost\").alias(\"AvgCost\")).show()\n",
    "df.groupBy(\"Gender\").agg(avg(\"TotalCost\").alias(\"AvgCost\")).show()\n",
    "df.groupBy(\"IncomeLevel\").agg(avg(\"TotalCost\").alias(\"AvgCost\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08e6463d-1c6b-4f5f-8462-e413b431c917",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n|TreatmentType|           AvgCost|\n+-------------+------------------+\n|      Therapy| 15176.58406994424|\n|   Medication|14916.026465789882|\n|      Surgery|14762.236168316846|\n+-------------+------------------+\n\n+------------------+------------------+\n|         Diagnosis|           AvgCost|\n+------------------+------------------+\n|          Diabetes|14865.651183282984|\n|Respiratory Issues|15045.227030393618|\n|      Hypertension|14930.694149195528|\n|            Cancer|14781.239489124975|\n|    Cardiac Issues|15057.791985851429|\n+------------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Analyze costs by treatments and diagnoses\n",
    "df.groupBy(\"TreatmentType\").agg(avg(\"TotalCost\").alias(\"AvgCost\")).show()\n",
    "df.groupBy(\"Diagnosis\").agg(avg(\"TotalCost\").alias(\"AvgCost\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfe2ee66-138c-4e9f-9168-5cca3094283e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 4866.718845729292\n"
     ]
    }
   ],
   "source": [
    "#Build a predictive model for estimating healthcare costs based on patient profiles and medical history\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Prepare features and labels\n",
    "feature_cols = [\"Age\", \"NumberOfVisits\", \"TreatmentDuration\", \"HospitalizationDays\", \n",
    "                \"MedicationCost\", \"DiagnosticTestCost\", \"SurgeryCost\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "df = assembler.transform(df)\n",
    "data = df.select(\"features\", col(\"TotalCost\").alias(\"label\"))\n",
    "\n",
    "# Split into training and test datasets\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Train a Linear Regression model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "model = lr.fit(train_data)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.transform(test_data)\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b58984a0-bc2b-4fd3-b5fa-19c2990c44eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between Age and TotalCost: 0.006291451628312267\nCorrelation between NumberOfVisits and TotalCost: 0.00400489744185796\nCorrelation between HospitalizationDays and TotalCost: 0.015517819582616232\nCorrelation between MedicationCost and TotalCost: -0.0010727881555040405\nCorrelation between DiagnosticTestCost and TotalCost: 0.021992242433913088\nCorrelation between SurgeryCost and TotalCost: 0.004978128281359015\n"
     ]
    }
   ],
   "source": [
    "3   #  Identify high-cost drivers to optimize and manage healthcare expenses effectively\n",
    "from pyspark.sql.functions import corr\n",
    "\n",
    "# Compute correlations with TotalCost\n",
    "for col_name in [\"Age\", \"NumberOfVisits\", \"HospitalizationDays\", \"MedicationCost\", \"DiagnosticTestCost\", \"SurgeryCost\"]:\n",
    "    correlation = df.select(corr(col_name, \"TotalCost\").alias(\"correlation\")).collect()[0][0]\n",
    "    print(f\"Correlation between {col_name} and TotalCost: {correlation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92c5848d-42f4-4b69-8024-c8a45d668dce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+------------------+\n|Year|Quarter|           AvgCost|\n+----+-------+------------------+\n|2020|     Q1|15167.513485804406|\n|2020|     Q2|14653.014424040051|\n|2020|     Q3|15260.646462585033|\n|2020|     Q4|14553.310030769244|\n|2021|     Q1|14835.016893819344|\n|2021|     Q2|14955.484741784043|\n|2021|     Q3|14956.208673300165|\n|2021|     Q4|14767.507511811029|\n|2022|     Q1|14974.168455414012|\n|2022|     Q2|14643.093106312288|\n|2022|     Q3|14541.001712962965|\n|2022|     Q4| 15036.64642967542|\n|2023|     Q1|15198.495357142858|\n|2023|     Q2|15097.901555555556|\n|2023|     Q3|15212.372683706057|\n|2023|     Q4|15155.305224358965|\n+----+-------+------------------+\n\n+-----------------+-----------------+\n|InsuranceCoverage|          AvgCost|\n+-----------------+-----------------+\n|             None|14845.49491159136|\n|          Partial|15047.36129994937|\n|             Full|14867.48369331743|\n+-----------------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "#4. Support decision-making with data-driven insights for cost management\n",
    "# Find cost trends by year and quarter\n",
    "df.groupBy(\"Year\", \"Quarter\").agg(avg(\"TotalCost\").alias(\"AvgCost\")).orderBy(\"Year\", \"Quarter\").show()\n",
    "\n",
    "# Identify cost differences by insurance coverage\n",
    "df.groupBy(\"InsuranceCoverage\").agg(avg(\"TotalCost\").alias(\"AvgCost\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a57e431-8e81-4fef-9c34-3e94fba4ead7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n|prediction|count|\n+----------+-----+\n|         1| 2771|\n|         2| 2614|\n|         0| 4615|\n+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "#5. Identify patterns to enable personalized, cost-effective care\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "# Apply K-Means clustering\n",
    "kmeans = KMeans(featuresCol=\"features\", k=3, seed=42)\n",
    "model = kmeans.fit(data)\n",
    "\n",
    "# Predict clusters\n",
    "clusters = model.transform(data)\n",
    "clusters.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0924069d-0353-49a4-84a0-ae760047ee19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----------------+\n|Year|Quarter|        TotalCost|\n+----+-------+-----------------+\n|2020|     Q1|9616203.549999993|\n|2020|     Q2|8777155.639999991|\n|2020|     Q3|       8973260.12|\n|2020|     Q4|9459651.520000009|\n|2021|     Q1|9360895.660000006|\n|2021|     Q2|9556554.750000004|\n|2021|     Q3|       9018593.83|\n|2021|     Q4|9377367.270000003|\n|2022|     Q1|       9403777.79|\n|2022|     Q2|8815142.049999997|\n|2022|     Q3|9422569.110000001|\n|2022|     Q4|9728710.239999996|\n|2023|     Q1|       9362273.14|\n|2023|     Q2|       9511677.98|\n|2023|     Q3|9522945.299999991|\n|2023|     Q4|9456910.459999993|\n+----+-------+-----------------+\n\n+------------+-----------------+-----------------+\n|    features|            label|       prediction|\n+------------+-----------------+-----------------+\n|[2023.0,2.0]|       9511677.98|9439016.544482052|\n|[2023.0,3.0]|9522945.299999991|9466899.194232196|\n|[2023.0,1.0]|       9362273.14|9411133.894731939|\n|[2020.0,1.0]|9616203.549999993|9175679.207267672|\n|[2020.0,3.0]|       8973260.12|9231444.506767929|\n|[2021.0,4.0]|9377367.270000003|9337812.052339494|\n|[2022.0,2.0]|8815142.049999997| 9360531.64866063|\n|[2021.0,1.0]|9360895.660000006|9254164.103089094|\n|[2021.0,2.0]|9556554.750000004|9282046.752839208|\n|[2020.0,4.0]|9459651.520000009|9259327.156518072|\n|[2023.0,4.0]|9456910.459999993|9494781.843982339|\n|[2021.0,3.0]|       9018593.83|9309929.402589351|\n|[2022.0,4.0]|9728710.239999996|9416296.948160917|\n|[2022.0,1.0]|       9403777.79|9332648.998910517|\n|[2022.0,3.0]|9422569.110000001|9388414.298410773|\n|[2020.0,2.0]|8777155.639999991|9203561.857017785|\n+------------+-----------------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "#6. Continuously monitor and forecast healthcare cost trends\n",
    "# Monitor cost trends over time\n",
    "df.groupBy(\"Year\", \"Quarter\").agg(sum(\"TotalCost\").alias(\"TotalCost\")).orderBy(\"Year\", \"Quarter\").show()\n",
    "\n",
    "# Forecasting: Use a linear regression model on yearly/quarterly data\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Convert Quarter to numerical values\n",
    "trends = trends.withColumn(\"QuarterNum\", \n",
    "                           when(trends[\"Quarter\"] == \"Q1\", 1)\n",
    "                           .when(trends[\"Quarter\"] == \"Q2\", 2)\n",
    "                           .when(trends[\"Quarter\"] == \"Q3\", 3)\n",
    "                           .when(trends[\"Quarter\"] == \"Q4\", 4))\n",
    "\n",
    "# Define feature columns for the assembler\n",
    "feature_cols = [\"Year\", \"QuarterNum\"]\n",
    "\n",
    "# Create feature vector\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "trends = assembler.transform(trends)\n",
    "\n",
    "# Select features and label for model training\n",
    "trends_data = trends.select(\"features\", col(\"TotalCost\").alias(\"label\"))\n",
    "\n",
    "# Train a linear regression model\n",
    "forecast_model = lr.fit(trends_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = forecast_model.transform(trends_data)\n",
    "predictions.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04a3c23a-1924-4380-a7d7-83e5de68983e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Bigdata Final Project",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
